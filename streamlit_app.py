import streamlit as st
import google.generativeai as genai

st.title("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.write(
    "ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ Google Gemini Flash-2.5 ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
)

api_key = st.secrets.get("gemini_api_key", "")

sp1 = '''
æ¸‹æ²¢æ „ä¸€ã«ã¤ã„ã¦ã®ã‚¯ã‚¤ã‚ºã‚’ï¼’å•ã€å‡ºé¡Œã—ã¦
'''

if not api_key:
    st.info("Gemini API ã‚­ãƒ¼ã‚’ .streamlit/secrets.toml ã® 'gemini_api_key' ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
else:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.5-flash")

    # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆå¤‰æ•°
    if "messages" not in st.session_state:
        # æœ€åˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
        st.session_state.messages = [
            {
                "role": "user",
                "content": sp1
            }
        ]
        # Gemini APIã§æœ€åˆã®ã‚¯ã‚¤ã‚ºå›ç­”ã‚’å–å¾—ã—ã¦è¿½åŠ 
        history = [{"role": "user", "parts": [sp1]}]
        try:
            response = model.generate_content(history)
            # Gemini APIã®å›ç­”æœ¬æ–‡ã‚’å–å¾—
            content = response.candidates[0].content.parts[0].text
            st.session_state.messages.append({"role": "assistant", "content": content})
        except Exception as e:
            st.session_state.messages.append({"role": "assistant", "content": f"ã‚¨ãƒ©ãƒ¼: {e}"})

    # æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    for message in st.session_state.messages:
        if message["role"] == "system":
            continue
        with st.chat_message("user" if message["role"] == "user" else "assistant"):
            st.markdown(message["content"])

    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ï¼ˆæ—¥æœ¬èªè¡¨ç¤ºï¼‰
    if prompt := st.chat_input("è³ªå•ã‚„å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Gemini API ç”¨ã«å±¥æ­´ã‚’æ•´å½¢
        history = []
        for m in st.session_state.messages:
            if m["role"] == "user":
                history.append({"role": "user", "parts": [m["content"]]})
            elif m["role"] == "assistant":
                history.append({"role": "model", "parts": [m["content"]]})

        try:
            response_stream = model.generate_content(
                history,
                stream=True,
            )
            with st.chat_message("assistant"):
                full_response = ""
                for chunk in response_stream:
                    if chunk.candidates and chunk.candidates[0].content.parts:
                        part = chunk.candidates[0].content.parts[0].text
                        st.write(part, end="")
                        full_response += part
                st.session_state.messages.append({"role": "assistant", "content": full_response})
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
