import streamlit as st
import google.generativeai as genai

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜ã‚’è¡¨ç¤º
st.title("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.write(
    "ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ Google Gemini Flash-2.5 ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
)

# Gemini API ã‚­ãƒ¼ã‚’ Streamlit ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰å–å¾—
api_key = st.secrets.get("gemini_api_key", "")

if not api_key:
    st.info("Gemini API ã‚­ãƒ¼ã‚’ .streamlit/secrets.toml ã® 'gemini_api_key' ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
else:
    # Google Generative AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®è¨­å®š
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("gemini-2.5-flash")

    # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆå¤‰æ•°
    if "messages" not in st.session_state:
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€åˆã«è¿½åŠ 
        st.session_state.messages = [
            {
                "role": "system",
                "content": "æ¸‹æ²¢æ „ä¸€ã«ã¤ã„ã¦ã®ã‚¯ã‚¤ã‚ºã‚’ï¼’å•ã€å‡ºé¡Œã—ã¦"
            }
        ]

    # æ—¢å­˜ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    for message in st.session_state.messages:
        # "system" ãƒ­ãƒ¼ãƒ«ã¯æ¡ˆå†…ã®ãŸã‚éè¡¨ç¤º
        if message["role"] == "system":
            continue
        with st.chat_message("user" if message["role"] == "user" else "assistant"):
            st.markdown(message["content"])

    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ï¼ˆæ—¥æœ¬èªè¡¨ç¤ºï¼‰
    if prompt := st.chat_input("è³ªå•ã‚„å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Gemini API ç”¨ã«å±¥æ­´ã‚’æ•´å½¢
        history = []
        for m in st.session_state.messages:
            # "system" ãƒ­ãƒ¼ãƒ«ã¯æœ€åˆã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦æ¸¡ã™
            if m["role"] == "system":
                history.append({"role": "system", "parts": [m["content"]]})
            elif m["role"] == "user":
                history.append({"role": "user", "parts": [m["content"]]})
            elif m["role"] == "assistant":
                history.append({"role": "model", "parts": [m["content"]]})

        # Gemini API ã§å›ç­”ç”Ÿæˆ
        try:
            response_stream = model.generate_content(
                history,
                stream=True,
            )
            # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã§å›ç­”ã‚’è¡¨ç¤º
            with st.chat_message("assistant"):
                full_response = ""
                for chunk in response_stream:
                    if chunk.candidates and chunk.candidates[0].content.parts:
                        part = chunk.candidates[0].content.parts[0].text
                        st.write(part, end="")
                        full_response += part
                st.session_state.messages.append({"role": "assistant", "content": full_response})
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
